{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1b1fb-67a4-45b0-a6c1-62884c54a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai pymongo bs4 openai tiktoken gradio requests lxml argparse unstructured boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca113021-5253-478e-b54b-bfc61f59c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import gradio as gr\n",
    "from gradio.themes.base import Base\n",
    "import key_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bffdd5c-becf-4b27-824a-e3053231302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各種変数の設定\n",
    "client = MongoClient(key_param.MONGO_URI)\n",
    "dbName = \"langchain_demo_ja\"\n",
    "collectionName = \"collection_of_text_blobs\"\n",
    "collection = client[dbName][collectionName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7d71e60-e747-482e-9c06-f6dfef1e11f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 4/4 [00:04<00:00,  1.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# ディレクトリ内のテキストファイルをdataオブジェクトに読み込む\n",
    "loader = DirectoryLoader( './sample_files_ja', glob=\"./*.txt\", show_progress=True)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1243d8ef-eec6-483e-8a9e-abd695addb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトル化を行うためのモデルを定義\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002', api_key=key_param.openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfeb970-0d4e-44f9-8cf8-65be6fd8fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data に対するベクトルを生成して、langchain_demo.collection_of_text_blobsコレクションに追加する\n",
    "vectorStore = MongoDBAtlasVectorSearch.from_documents( data, embeddings, collection=collection, index_name='langchain_demo_ja' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87ea1070-9c22-44a6-bc6e-60c6ef62eb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n  \"fields\": [{\\n    \"path\": \"embedding\",\\n    \"numDimensions\": 1536,\\n    \"similarity\": \"cosine\",\\n    \"type\": \"vector\"\\n  }]\\n}\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注：この先に進む前にAtlas UIでlangchain_demo.collection_of_text_blobsコレクションに対して\n",
    "# 以下のVector Searchのインデックスを作成する\n",
    "\n",
    "#index名: langchain_demo_ja\n",
    "\n",
    "'''\n",
    "{\n",
    "  \"fields\": [{\n",
    "    \"path\": \"embedding\",\n",
    "    \"numDimensions\": 1536,\n",
    "    \"similarity\": \"cosine\",\n",
    "    \"type\": \"vector\"\n",
    "  }]\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9079408e-09e1-4a04-86f0-a6868986700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_data(query):\n",
    "    # OpenAIの埋め込みを使って質問をベクトルに変換し、\n",
    "    # LangchainのvectorStoreを使って質問内容に関連のある文書をAtlas VectorSearchで検索し、\n",
    "    # その文書の内容を考慮した回答を生成する\n",
    "\n",
    "    # 質問文に最も関連がある文書1つをAtlas VectorSearchのsimilarity_searchで抽出\n",
    "    docs = vectorStore.similarity_search(query, K=1)\n",
    "    as_output = docs[0].page_content\n",
    "\n",
    "    # 回答文生成に利用するOpenAIのLLMモデルを定義\n",
    "    llm = OpenAI(model='gpt-3.5-turbo-instruct', api_key=key_param.openai_api_key, temperature=0)\n",
    "    template = \"\"\"Question: {question}\n",
    "    Answer: \"\"\"\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    raw_answer = llm_chain.run(query)\n",
    "\n",
    "    # OpenAIの文書生成モデルとAtlas VectorSearchを用いて、質問文に関連がある文書を踏まえた回答を生成\n",
    "    retriever = vectorStore.as_retriever()\n",
    "    qa = RetrievalQA.from_chain_type(llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    retriever_output = qa.invoke(query)\n",
    "\n",
    "    # as_outout: 質問と関連が高い文書の内容\n",
    "    # retriever_output: 上記の文書を踏まえて生成された回答内容\n",
    "    return raw_answer, as_output, retriever_output['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ca29405-7016-41a2-822c-6fd14988863e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# デモ画面の生成\n",
    "with gr.Blocks(theme=Base(), title=\"Atlas Vector Search と RAG Architecture を使った質問回答アプリ\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        #  Atlas Vector Search と RAG Architecture を使った質問回答アプリ\n",
    "        質問例\n",
    "        1. 2月13日の日経平均ニュースを教えてください\n",
    "        2. アルフレッドはどのような質問をしましたか？\n",
    "        3. アルフレッドはブルースとどのような会話をしましたか？CSATはどのくらいでしたか？\n",
    "        4. yawとはなんですか?\n",
    "        \"\"\")\n",
    "    textbox = gr.Textbox(label=\"Enter your Question:\")\n",
    "    with gr.Row():\n",
    "        button = gr.Button(\"Submit\", variant=\"primary\")\n",
    "    with gr.Column():\n",
    "        output1 = gr.Textbox(lines=1, max_lines=10, label=\"Output with just LLM model:\")\n",
    "        output2 = gr.Textbox(lines=1, max_lines=10, label=\"Output with just Atlas Vector Search (returns text field as is):\")\n",
    "        output3 = gr.Textbox(lines=1, max_lines=10, label=\"Output generated by chaining Atlas Vector Search to Langchain's RetrieverQA + OpenAI LLM:\")\n",
    "\n",
    "# Call query_data function upon clicking the Submit button\n",
    "\n",
    "    button.click(query_data, textbox, outputs=[output1, output2, output3])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56740049-1605-44d3-a0f6-601f04d6147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 回答文生成に利用するOpenAIのLLMモデルを定義\n",
    "    question='2月13日のニュースを教えて'\n",
    "    llm = OpenAI(model='gpt-3.5-turbo-instruct', api_key=key_param.openai_api_key, temperature=0)\n",
    "    template = \"\"\"Question: {question}\n",
    "    Answer: \"\"\"\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    result = llm_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c810e436-2248-4777-91e7-b6eca12fb382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2月13日のニュースは、以下のようなものがあります。\\n\\n1. 新型コロナウイルスの感染拡大が続く中、政府は緊急事態宣言を延長する方針を決定しました。延長期間は3月7日までとなります。\\n\\n2. 東京都では、新たに393人の新型コロナウイルス感染者が確認されました。また、重症者数も過去最多の142人となり、医療体制が逼迫しています。\\n\\n3. 日本政府は、新型コロナウイルスワクチンの接種を開始しました。まずは医療従事者を対象に、2月17日から接種が始まります。\\n\\n4. 北海道では、大雪による交通機関の乱れや停'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab5d057-7c0a-4dcf-851a-017fc249e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問例\n",
    "# 1. 2月１３日のニュースを教えてください\n",
    "# 2. アルフレッドはどのような質問をしましたか？日本語の箇条書きでまとめてください。\n",
    "# 3. アルフレッドはブルースとどのような会話をしましたか？CSATはどのくらいでしたか？\n",
    "# 4. yawとはなんですか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17244f-176f-4454-bdf4-9926dc2a5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question Answering App using Vector Search + RAG\n",
    "# 1. Did any error occur on August 16th? If yes, then what was the error caused by?\\n\",\n",
    "# 2. What questions did Alfread あsk?What were Bruce's answers? Please summarize in bullet points.\\n\",\n",
    "# 3. What was the overall sentiment of Alfred's chat with Bruce? What was the likely CSAT?\\n\",\n",
    "# 4. What's yaw?\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
