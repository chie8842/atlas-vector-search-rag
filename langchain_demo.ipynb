{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c1b1fb-67a4-45b0-a6c1-62884c54a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-openai pymongo bs4 openai tiktoken gradio requests lxml argparse unstructured boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca113021-5253-478e-b54b-bfc61f59c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import MongoDBAtlasVectorSearch\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "import gradio as gr\n",
    "from gradio.themes.base import Base\n",
    "import key_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bffdd5c-becf-4b27-824a-e3053231302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各種変数の設定\n",
    "client = MongoClient(key_param.MONGO_URI)\n",
    "dbName = \"langchain_demo\"\n",
    "collectionName = \"collection_of_text_blobs\"\n",
    "collection = client[dbName][collectionName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7d71e60-e747-482e-9c06-f6dfef1e11f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█| 3/3 [00:00<00:00\n"
     ]
    }
   ],
   "source": [
    "# ディレクトリ内のテキストファイルをdataオブジェクトに読み込む\n",
    "loader = DirectoryLoader( './sample_files', glob=\"./*.txt\", show_progress=True)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1243d8ef-eec6-483e-8a9e-abd695addb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトル化を行うためのモデルを定義\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-ada-002', api_key=key_param.openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddfeb970-0d4e-44f9-8cf8-65be6fd8fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data に対するベクトルを生成して、langchain_demo.collection_of_text_blobsコレクションに追加する\n",
    "vectorStore = MongoDBAtlasVectorSearch.from_documents( data, embeddings, collection=collection, index_name='langchain_demo' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87ea1070-9c22-44a6-bc6e-60c6ef62eb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n  \"fields\": [{\\n    \"path\": \"embedding\",\\n    \"numDimensions\": 1536,\\n    \"similarity\": \"cosine\",\\n    \"type\": \"vector\"\\n  }]\\n}\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 注：この先に進む前にAtlas UIでlangchain_demo.collection_of_text_blobsコレクションに対して\n",
    "# 以下のVector Searchのインデックスを作成する\n",
    "\n",
    "'''\n",
    "{\n",
    "  \"fields\": [{\n",
    "    \"path\": \"embedding\",\n",
    "    \"numDimensions\": 1536,\n",
    "    \"similarity\": \"cosine\",\n",
    "    \"type\": \"vector\"\n",
    "  }]\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9079408e-09e1-4a04-86f0-a6868986700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_data(query):\n",
    "    # OpenAIの埋め込みを使って質問をベクトルに変換し、\n",
    "    # LangchainのvectorStoreを使って質問内容に関連のある文書をAtlas VectorSearchで検索し、\n",
    "    # その文書の内容を考慮した回答を生成する\n",
    "\n",
    "    # 質問文に最も関連がある文書1つをAtlas VectorSearchのsimilarity_searchで抽出\n",
    "    docs = vectorStore.similarity_search(query, K=1)\n",
    "    as_output = docs[0].page_content\n",
    "\n",
    "    # 回答文生成に利用するOpenAIのLLMモデルを定義\n",
    "    llm = OpenAI(model='gpt-3.5-turbo-instruct', api_key=key_param.openai_api_key, temperature=0)\n",
    "\n",
    "    # OpenAIの文書生成モデルとAtlas VectorSearchを用いて、質問文に関連がある文書を踏まえた回答を生成\n",
    "    retriever = vectorStore.as_retriever()\n",
    "    qa = RetrievalQA.from_chain_type(llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    retriever_output = qa.invoke(query)\n",
    "\n",
    "    # as_outout: 質問と関連が高い文書の内容\n",
    "    # retriever_output: 上記の文書を踏まえて生成された回答内容\n",
    "    return as_output, retriever_output['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ca29405-7016-41a2-822c-6fd14988863e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# デモ画面の生成\n",
    "with gr.Blocks(theme=Base(), title=\"Question Answering App using Vector Search + RAG\") as demo:\n",
    "    gr.Markdown(\n",
    "        \"\"\"\n",
    "        # Question Answering App using Atlas Vector Search + RAG Architecture\n",
    "        \"\"\")\n",
    "    textbox = gr.Textbox(label=\"Enter your Question:\")\n",
    "    with gr.Row():\n",
    "        button = gr.Button(\"Submit\", variant=\"primary\")\n",
    "    with gr.Column():\n",
    "        output1 = gr.Textbox(lines=1, max_lines=10, label=\"Output with just Atlas Vector Search (returns text field as is):\")\n",
    "        output2 = gr.Textbox(lines=1, max_lines=10, label=\"Output generated by chaining Atlas Vector Search to Langchain's RetrieverQA + OpenAI LLM:\")\n",
    "\n",
    "# Call query_data function upon clicking the Submit button\n",
    "\n",
    "    button.click(query_data, textbox, outputs=[output1, output2])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aab5d057-7c0a-4dcf-851a-017fc249e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問例\n",
    "# 1. 8月16日にエラーは発生しましたか？もしそうなら、そのエラーの原因は何ですか？\n",
    "# 2. アルフレッドはどのような質問をしましたか？日本語の箇条書きでまとめてください。\n",
    "# 3. アルフレッドはブルースとどのような会話をしましたか？CSATはどのくらいでしたか？\n",
    "# 4. yawとはなんですか?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17244f-176f-4454-bdf4-9926dc2a5dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
